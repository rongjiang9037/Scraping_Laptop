{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import time\n",
    "# from sql_queries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for all laptops on B&H website\n",
    "theurl = 'https://www.bhphotovideo.com/c/buy/laptops/ci/18818/N/4110474292/pn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laptop table insert query\n",
    "laptop_table_insert = \"\"\"INSERT INTO dimlaptop (name, sku, url)\n",
    "                            SELECT name, sku, url\n",
    "                            FROM staging_laptop\n",
    "                            ON CONFLICT (sku)\n",
    "                            DO UPDATE SET name = excluded.name,\n",
    "                                          url = excluded.url;\n",
    "                      \"\"\"\n",
    "\n",
    "staging_table_insert = \"\"\"INSERT INTO staging_laptop (name, time, brand, sku, price, url, availability, review_num)\n",
    "                                VALUES ( %(name)s,\n",
    "                                         %(time)s,\n",
    "                                         %(brand)s,\n",
    "                                         %(sku)s,\n",
    "                                         %(price)s,\n",
    "                                         %(url)s,\n",
    "                                         %(availability)s,\n",
    "                                         %(review_num)s\n",
    "                                        )\n",
    "                                ON CONFLICT (sku)\n",
    "                                DO UPDATE SET name = excluded.name,\n",
    "                                              time = excluded.time,\n",
    "                                              brand = excluded.brand,\n",
    "                                              sku = excluded.sku,\n",
    "                                              price = excluded.price,\n",
    "                                              url = excluded.url,\n",
    "                                              availability = excluded.availability,\n",
    "                                              review_num = excluded.review_num;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_table_create = \"\"\"CREATE TABLE IF NOT EXISTS staging_laptop\n",
    "                                (   ID SERIAL PRIMARY KEY,\n",
    "                                    time date NOT NULL,\n",
    "                                    name varchar NOT NULL,\n",
    "                                    brand varchar NOT NULL,\n",
    "                                    sku varchar NOT NULL,\n",
    "                                    price numeric,\n",
    "                                    url varchar NOT NULL,\n",
    "                                    availability varchar,\n",
    "                                    review_num integer,\n",
    "                                UNIQUE(sku)\n",
    "                                )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_table_insert = \"\"\"INSERT INTO dimbrand (name, ticker, exchange_nm)\n",
    "                            VALUES (%(name)s,\n",
    "                                    %(ticker)s,\n",
    "                                    %(exchange_nm)s)\n",
    "                            ON CONFLICT (name)\n",
    "                            DO UPDATE SET ticker = excluded.ticker,\n",
    "                                          exchange_nm = excluded.exchange_nm;\n",
    "\"\"\"\n",
    "brand_table_insert_from_staging = \"\"\"INSERT INTO dimbrand (name, ticker, exchange_nm)\n",
    "                                        SELECT DISTINCT brand, null, null\n",
    "                                            FROM staging_laptop\n",
    "                                    ON CONFLICT \n",
    "                                    DO NOTHING\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table_insert = \"\"\"INSERT INTO dimtime (time, day, week, month, year, weekday)\n",
    "                            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                       ON CONFLICT (time)\n",
    "                       DO NOTHING\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptopinfo_table_insert = \"\"\"INSERT INTO factlaptopinfo (time, laptop_key, brand_key, price, availability, review_num)\n",
    "                                SELECT %(time)s, \n",
    "                                       laptop.laptop_key, \n",
    "                                       brand.brand_key,\n",
    "                                       staging.price,\n",
    "                                       staging.availability,\n",
    "                                       staging.review_num\n",
    "                                FROM staging_laptop staging\n",
    "                                JOIN dimlaptop laptop ON (staging.sku = laptop.sku)\n",
    "                                JOIN dimbrand brand ON (staging.brand = brand.name);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_table_delete = \"\"\"DROP TABLE IF EXISTS staging_laptop;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_info(soup):\n",
    "    \"\"\"\n",
    "    This function page information from each page.\n",
    "    \n",
    "    input:\n",
    "    soup - beautiful soup object\n",
    "    \n",
    "    return:\n",
    "    page - page info\n",
    "    \"\"\"\n",
    "    # get all script snippets of type 'text/javascript'\n",
    "    js_info = soup.find_all(\"script\", attrs={\"type\":\"text/javascript\"})\n",
    "    \n",
    "    which_page = None\n",
    "    \n",
    "    # loop over each of them, looking for page info\n",
    "    for s in js_info:\n",
    "        try:\n",
    "            which_page = re.search('\\\"page\\\" : (\\d+),', s.text).group(1)\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "    return int(which_page) if which_page else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_last_page(soup, curr_page):\n",
    "    \"\"\"\n",
    "    Determine whether the scraped page is the last page.\n",
    "    If it's the last page, B&H will redirect scraper to page 1.\n",
    "    \n",
    "    input:\n",
    "    soup - beautiful soup object\n",
    "    curr_page - the current scraping page\n",
    "    \n",
    "    return:\n",
    "    is_last_page - True/False\n",
    "    \"\"\"\n",
    "    if curr_page != 1 and get_page_info(soup) <= 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_availibility_info(info_str):\n",
    "    \"\"\"\n",
    "    This function extract availibility info.\n",
    "    \n",
    "    input:\n",
    "    info_str - string of availability\n",
    "    \n",
    "    return: 'in stock' / ''\n",
    "    \"\"\"\n",
    "    info_str = info_str.lower()\n",
    "    if 'in stock' in info_str:\n",
    "        return 'in stock'\n",
    "    elif 'back-ordered' in info_str:\n",
    "        return 'back-ordered'\n",
    "    elif 'new item' in info_str:\n",
    "        return 'new item'\n",
    "    elif 'more on the way' in info_str:\n",
    "        return 'more on the way'\n",
    "    else:\n",
    "        return 'not available'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_laptop_from_page(soup):\n",
    "    \"\"\"\n",
    "    Retrieve laptop related information from the page.\n",
    "    - Product Name\n",
    "    - Product Brand\n",
    "    - Product SKU\n",
    "    - Product Price\n",
    "    - Product URL\n",
    "    - Product Availability\n",
    "    - Product # of Reviews\n",
    "    \n",
    "    input:\n",
    "    soup - beautiful soup object\n",
    "    \n",
    "    output:\n",
    "    page_info_dict - dictionary of each product\n",
    "    \"\"\"\n",
    "    # return a list of laptop info from \"itemDetail\" divs\n",
    "    products = soup.find_all('div', attrs={'data-selenium':'itemDetail'})\n",
    "    \n",
    "    for product in products:\n",
    "        try:\n",
    "            # empty dictionary\n",
    "            product_dict = {}\n",
    "            \n",
    "            # get current date as time\n",
    "            product_dict['time'] = np.datetime_as_string(np.datetime64('now'), unit='D')\n",
    "\n",
    "            # get product name\n",
    "            ProductName = product.find(\"span\", attrs={'itemprop':'name'}).text.strip()\n",
    "            product_dict['name'] = ProductName.lower()\n",
    "\n",
    "            # get product brand\n",
    "            ProductBrand = product.find(\"span\", attrs={'itemprop':'brand'}).text.strip()\n",
    "            product_dict['brand'] = ProductBrand.lower()\n",
    "\n",
    "            # get product sku\n",
    "            ProductInfoDict = json.loads(product['data-itemdata'])\n",
    "            product_dict['sku'] = ProductInfoDict['sku']\n",
    "\n",
    "            # get product price\n",
    "            try: \n",
    "                product_dict['price'] = float(ProductInfoDict['price'])\n",
    "            except:\n",
    "                product_dict['price'] = None\n",
    "\n",
    "            # get product URL\n",
    "            product_dict['url'] = product.find(\"a\", attrs={\"class\":\"itemImg\"})['href'].lower()\n",
    "\n",
    "\n",
    "            # get product availability info\n",
    "            productAvalability = product.find(\"div\", attrs={\"data-selenium\":\"salesComments\"}).text.strip()\n",
    "            product_dict['availability'] = extract_availibility_info(productAvalability)\n",
    "\n",
    "            # get number of reviews\n",
    "            try:\n",
    "                reviews_str = product.find(\"a\", attrs={'data-selenium':'itemReviews'}).text.strip()\n",
    "                reviews_str = re.findall(re.compile(r'\\((\\d+)\\)'), reviews_str)[0]\n",
    "                reviews_int = int(reviews_str)\n",
    "            except:\n",
    "                reviews_int = 0\n",
    "            product_dict['review_num'] = reviews_int\n",
    "        \n",
    "        except:\n",
    "            logging.info('An Error Ocurred for product {}.'.format(ProductName))\n",
    "            continue\n",
    "            \n",
    "        yield product_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_laptop_from_site():\n",
    "    \"\"\"\n",
    "    It's a generator function.\n",
    "    It scrapes data from URL 'https://www.bhphotovideo.com/c/buy/laptops/ci/18818/N/4110474292',\n",
    "    and return product information.\n",
    "    \n",
    "    input:\n",
    "    page_size - the number of pages in total to search on B&H laptop section\n",
    "    \n",
    "    output:\n",
    "    product_info - a dictionary contains all necessary info for one product  \n",
    "    \"\"\"\n",
    "    # B&H laptop URL\n",
    "    url = 'https://www.bhphotovideo.com/c/buy/laptops/ci/18818/N/4110474292/pn/'\n",
    "    # scrape from the first page\n",
    "    page = 1\n",
    "    \n",
    "    while True:\n",
    "        # make request for each page, get source code and parse with BeautifulSoup\n",
    "        try:\n",
    "            req = Request(url+str(page), headers = {'User-Agent':'Mozilla/5.0'})\n",
    "            thepage = urlopen(req).read()\n",
    "            page_soup = BeautifulSoup(thepage, 'html.parser')\n",
    "        except Exception as e:\n",
    "            logging.info(f\"ERROR ocurred when scraping data for page {page}.\")\n",
    "            logging.info(f\"ERROR message: {e}\")\n",
    "            break\n",
    "            \n",
    "        # if last page is reached, exit\n",
    "        if is_last_page(page_soup, page):\n",
    "            logging.info(\"Finished scraping all the data.\")\n",
    "            break\n",
    "        \n",
    "        #parse data on this page\n",
    "        product_info = iter_laptop_from_page(page_soup)\n",
    "        \n",
    "        # break loop if product_info is None\n",
    "        if not product_info:\n",
    "            break\n",
    "            \n",
    "        yield from product_info\n",
    "        \n",
    "        # move to the next page\n",
    "        page += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(cur, conn):\n",
    "    \"\"\"\n",
    "    - Scrape laptop data\n",
    "    \n",
    "    - create staging_laptop table\n",
    "    - Store scraped data into staging_laptop table\n",
    "    \n",
    "    - extract data from staging_laptop into laptop table\n",
    "    - extract data from staging_laptop into brand table\n",
    "    \n",
    "    input: \n",
    "    cur - cursor variable\n",
    "    conn - database connection\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # get all laptop info and save it as a list\n",
    "        all_laptop_iter = iter_laptop_from_site()\n",
    "\n",
    "        # create staging table\n",
    "        cur.execute(staging_table_create)\n",
    "        print(\"Created staging_laptop table.\")\n",
    "\n",
    "        # insert into staging table\n",
    "        psycopg2.extras.execute_batch(cur, staging_table_insert, all_laptop_iter)\n",
    "        conn.commit()\n",
    "        print(\"Successfully inserted scrapted data into the staging table.\")\n",
    "\n",
    "        # extract data from staging table and insert into dimlaptop table\n",
    "        cur.execute(laptop_table_insert)\n",
    "        print(\"Successfully inserted scrapted data into laptop table\")\n",
    "        \n",
    "        # extract brand data from staging table and insert into dimlaptop table\n",
    "        cur.execute(brand_table_insert_from_staging)\n",
    "\n",
    "        # extract data from ticker_csv and insert into brand table\n",
    "        df_ticker = pd.read_csv('../data/brand_ticker_info.csv')\n",
    "        df_ticker = df_ticker.rename(columns={'brand':'name'})\n",
    "        psycopg2.extras.execute_batch(cur, brand_table_insert, df_ticker.to_dict(orient='records'))\n",
    "        conn.commit()\n",
    "        print(\"Successfully inserted data into brand table.\")\n",
    "\n",
    "        # extract time info from staging_laptop table\n",
    "        cur.execute(\"SELECT DISTINCT time FROM staging_laptop;\")\n",
    "        curr_time = cur.fetchone()[0]\n",
    "\n",
    "        # convert np.datetime format to pd.timestamp\n",
    "        time_dt = pd.to_datetime(curr_time)\n",
    "        time_str = time_dt.strftime(\"%Y-%m-%d\")\n",
    "        cur.execute(time_table_insert, (curr_time, time_dt.day, \n",
    "                                        time_dt.week, time_dt.month, time_dt.year, time_dt.dayofweek))\n",
    "        conn.commit()\n",
    "        print(\"Successfully inserted data into time table.\")\n",
    "\n",
    "        # insert laptop info into laptop table\n",
    "        cur.execute(laptopinfo_table_insert, {'time':time_str})\n",
    "        conn.commit()\n",
    "        print(\"Successfully inserted data into laptopinfo table.\")\n",
    "\n",
    "        # delete staging table\n",
    "        cur.execute(staging_table_delete)\n",
    "        conn.commit()\n",
    "        print(\"Deleted staging_laptop table.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        conn.rollback()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    - Connect to sparkifydb database\n",
    "    \n",
    "    - get cursor variable\n",
    "    \n",
    "    - process data stored in file path 'data/song_data' & 'data/log_data'\n",
    "    \n",
    "    - close database connection\n",
    "    \n",
    "    input: None\n",
    "    return: None\n",
    "    \"\"\"\n",
    "    # connect to database\n",
    "    print(\"Started to scrape data for {}\".format(np.datetime_as_string(np.datetime64('now'), unit='D')))\n",
    "    conn = psycopg2.connect(host='localhost', \n",
    "                            dbname='bnhlaptop', \n",
    "                            password='test', \n",
    "                            port=5432, \n",
    "                            user='postgres')\n",
    "    cur = conn.cursor()\n",
    "    print(\"Connected to database bnhlaptop.\")\n",
    "    \n",
    "    # process data\n",
    "    process_data(cur, conn)\n",
    "\n",
    "    # close database connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
